#include "whisper_audio.h"
#include "audio.h"
#include "feature_extractor.h"
#include <iostream>
#include <vector>
#include <cassert>
#include <cmath>  // For M_PI
#include <iomanip>  // For std::setprecision
#include <fstream>  // For file existence check
#include <map>  // For std::map

/**
 * Simple test to demonstrate whisper audio processing integration using real audio
 */
void test_whisper_audio(const std::string& audio_filename = "001.wav") {
  std::cout << "=== Whisper Audio Processing Integration Test ===" << std::endl;

  // Test 1: Load real audio file from assets
  std::cout << "Loading audio file: " << audio_filename << " from assets..." << std::endl;

  std::string audio_file_path;

  // Try different possible asset paths depending on where we're running from
  std::vector<std::string> possible_paths = {
    "../../../main/assets/" + audio_filename,  // From CMake build directory (test_build/)
    "../../main/assets/" + audio_filename,  // From test directory directly
    "../../assets/" + audio_filename,  // Legacy path
    "../assets/" + audio_filename,     // From direct compilation
    "assets/" + audio_filename         // From project root
  };

  // Find the first path that exists
  bool found_file = false;
  for (const auto& path : possible_paths) {
    std::ifstream test_file(path);
    if (test_file.good()) {
      audio_file_path = path;
      found_file = true;
      break;
    }
  }

  if (!found_file) {
    std::cerr << "✗ Error: Could not find audio file " << audio_filename << std::endl;
    std::cerr << "  Searched paths:" << std::endl;
    for (const auto& path : possible_paths) {
      std::cerr << "    - " << path << std::endl;
    }
    throw std::runtime_error("Audio file not found: " + audio_filename);
  }

  audio_file_path = found_file ? audio_file_path : possible_paths[0];
  std::vector<float> test_audio;

  try {
    test_audio = Audio::decode_audio(audio_file_path, WHISPER_SAMPLE_RATE);
    if (test_audio.empty()) {
      throw std::runtime_error("Failed to load audio file (empty): " + audio_filename);
    }

    {
      // Store original size before potential trimming
      size_t original_size = test_audio.size();
      float original_duration = original_size / float(WHISPER_SAMPLE_RATE);

      std::cout << "✓ Successfully loaded " << audio_filename << " (" << original_size << " samples, "
                << original_duration << " seconds)" << std::endl;

      // For very large files, let's test with just the first portion to avoid memory issues
      if (test_audio.size() > WHISPER_SAMPLE_RATE * 30) {  // If longer than 30 seconds
        std::cout << "  → File is very large, using first 30 seconds for testing" << std::endl;
        test_audio.resize(WHISPER_SAMPLE_RATE * 30);
        std::cout << "  → Trimmed to " << test_audio.size() << " samples ("
                  << (test_audio.size() / float(WHISPER_SAMPLE_RATE)) << " seconds)" << std::endl;
      }
    }
  } catch (const std::exception& e) {
    std::cerr << "✗ Error loading " << audio_filename << ": " << e.what() << std::endl;
    throw;
  }

  // Test 2: Test audio preprocessing functions
  std::cout << "Testing audio preprocessing..." << std::endl;

  // Test normalization
  auto normalized_audio = whisper::AudioProcessor::normalize_audio(test_audio);
  std::cout << "✓ Audio normalization completed" << std::endl;

  // Test padding/trimming
  auto padded_audio = Audio::pad_or_trim(normalized_audio,
                                                           WHISPER_CHUNK_SIZE);  // Remove whisper:: namespace
  std::cout << "✓ Audio padding/trimming completed. Size: " << padded_audio.size() << std::endl;

  // Test pre-emphasis filter
  auto filtered_audio = whisper::AudioProcessor::apply_preemphasis(padded_audio);
  std::cout << "✓ Pre-emphasis filter applied" << std::endl;

  // Test 3: Test mel spectrogram extraction
  std::cout << "Testing mel spectrogram extraction..." << std::endl;
  auto mel_spectrogram = whisper::AudioProcessor::extract_mel_spectrogram(filtered_audio);

  if (!mel_spectrogram.empty()) {
    std::cout << "✓ Mel spectrogram extracted. Dimensions: "
              << mel_spectrogram.size() << " x "
              << mel_spectrogram[0].size() << std::endl;

    // Apply log transform
    auto log_mel_spectrogram = whisper::AudioProcessor::apply_log_transform(mel_spectrogram);
    std::cout << "✓ Log transform applied" << std::endl;
  } else {
    std::cout << "✗ Failed to extract mel spectrogram" << std::endl;
  }

  // Test 4: Test integration with Audio using real file
  std::cout << "Testing Audio integration..." << std::endl;

  // Load the file fresh to show actual properties (not trimmed version)
  auto full_audio = Audio::decode_audio(audio_file_path, WHISPER_SAMPLE_RATE);

  std::cout << "✓ Audio successfully loaded: " << audio_file_path << std::endl;
  std::cout << "Audio properties:" << std::endl;
  std::cout << "  - Samples: " << full_audio.size() << std::endl;
  std::cout << "  - Duration: " << (full_audio.size() / float(WHISPER_SAMPLE_RATE)) << " seconds" << std::endl;
  std::cout << "  - Sample Rate: " << WHISPER_SAMPLE_RATE << " Hz" << std::endl;

  // Show some sample values
  if (full_audio.size() >= 10) {
    std::cout << "  - First 10 samples: ";
    for (int i = 0; i < 10; ++i) {
      std::cout << std::fixed << std::setprecision(3) << full_audio[i] << " ";
    }
    std::cout << std::endl;
  }

  // Test 5: Test FeatureExtractor integration
  std::cout << "Testing FeatureExtractor integration..." << std::endl;
  FeatureExtractor extractor(80, 16000, 160, 30, 400);

  auto features = extractor.extract(filtered_audio);
  if (!features.empty()) {
    std::cout << "✓ FeatureExtractor integration successful. Features: "
              << features.size() << " x "
              << (features.empty() ? 0 : features[0].size()) << std::endl;
  } else {
    std::cout << "✓ FeatureExtractor fallback to original implementation" << std::endl;
  }

  std::cout << "=== Integration Test Completed ===" << std::endl;
}

/**
 * Usage example for whisper audio processing with different audio files
 */
void demonstrate_usage() {
  std::cout << "\n=== Usage Example ===" << std::endl;

  std::cout << "// Example usage in your application with different audio files:" << std::endl;
  std::cout << "// 1. Load any audio file from assets:" << std::endl;
  std::cout << "//    auto audio = Audio::decode_audio(\"assets/002-01.wav\", 16000);  // Large file" << std::endl;
  std::cout << "//    auto audio = Audio::decode_audio(\"assets/001.wav\", 16000);     // Smaller file" << std::endl;
  std::cout << "//    auto audio = Audio::decode_audio(\"assets/test.wav\", 16000);    // Test file" << std::endl;
  std::cout << "//    // For large files, consider processing in chunks" << std::endl;
  std::cout << "//" << std::endl;
  std::cout << "// 2. Test with different files:" << std::endl;
  std::cout << "//    test_whisper_audio(\"002-01.wav\");  // Large Arabic file" << std::endl;
  std::cout << "//    test_whisper_audio(\"001.wav\");     // Medium file" << std::endl;
  std::cout << "//    test_whisper_audio(\"test.wav\");    // Small test file" << std::endl;
  std::cout << "//" << std::endl;
  std::cout << "// 3. Preprocess audio with whisper-compatible functions:" << std::endl;
  std::cout << "//    auto normalized = whisper::AudioProcessor::normalize_audio(audio);" << std::endl;
  std::cout << "//    auto padded = Audio::pad_or_trim(normalized, WHISPER_CHUNK_SIZE);" << std::endl;
  std::cout << "//    auto filtered = whisper::AudioProcessor::apply_preemphasis(padded);" << std::endl;
  std::cout << "//" << std::endl;
  std::cout << "// 4. Extract features for whisper model:" << std::endl;
  std::cout << "//    FeatureExtractor extractor;" << std::endl;
  std::cout << "//    auto features = extractor.extract(filtered);" << std::endl;
  std::cout << "//" << std::endl;
  std::cout << "// 5. Pass features to your whisper model:" << std::endl;
  std::cout << "//    WhisperModel model(\"path/to/model\");" << std::endl;
  std::cout << "//    auto [segments, info] = model.transcribe(audio, \"ar\", true);" << std::endl;

  std::cout << "\n// Key benefits:" << std::endl;
  std::cout << "// - Flexible audio file testing with any file in assets/" << std::endl;
  std::cout << "// - Real audio file support through Audio" << std::endl;
  std::cout << "// - Whisper-compatible audio preprocessing" << std::endl;
  std::cout << "// - Proper 16kHz sampling rate handling" << std::endl;
  std::cout << "// - Mel spectrogram extraction matching whisper.cpp" << std::endl;
  std::cout << "// - Arabic language support for transcription" << std::endl;
  std::cout << "// - Integrated with existing Android NDK codebase" << std::endl;

  std::cout << "\n// Available test files:" << std::endl;
  std::cout << "// - 002-01.wav (28MB) - Large Arabic audio file" << std::endl;
  std::cout << "// - 001.wav (1.3MB) - Medium audio file" << std::endl;
  std::cout << "// - test.wav (130KB) - Small test file" << std::endl;
  std::cout << "// - Besmellah.m4a - M4A format (if supported)" << std::endl;
  std::cout << "// - Automatic resampling to 16kHz if needed" << std::endl;
  std::cout << "// - Smart chunking for large files to manage memory" << std::endl;
}

/**
 * Test comprehensive 60+ second audio processing pipeline
 */
void test_long_audio_integration(const std::string& audio_filename = "002-01.wav") {
  std::cout << "\n=== Long Audio Integration Test (60+ seconds) ===" << std::endl;
  std::cout << "Testing comprehensive pipeline with: " << audio_filename << std::endl;

  // Test different file paths for assets
  std::vector<std::string> possible_paths = {
    "../../../src/main/assets/" + audio_filename,
    "../../../main/assets/" + audio_filename,
    "../../assets/" + audio_filename,
    "../assets/" + audio_filename,
    "assets/" + audio_filename
  };

  std::string audio_file_path;
  bool found_file = false;

  // Find the first path that exists
  for (const auto& path : possible_paths) {
    std::ifstream test_file(path);
    if (test_file.good()) {
      audio_file_path = path;
      found_file = true;
      break;
    }
  }

  if (!found_file) {
    std::cerr << "✗ Error: Could not find audio file " << audio_filename << std::endl;
    std::cerr << "  Searched paths:" << std::endl;
    for (const auto& path : possible_paths) {
      std::cerr << "    - " << path << std::endl;
    }
    throw std::runtime_error("Audio file not found: " + audio_filename);
  }

  audio_file_path = found_file ? audio_file_path : possible_paths[0];

  // Test 1: Load and analyze large audio file
  std::cout << "\n1. Loading and analyzing large audio file..." << std::endl;

  std::vector<float> long_audio;
  float original_duration = 0.0f;

  try {
    long_audio = Audio::decode_audio(audio_file_path, WHISPER_SAMPLE_RATE);

    if (long_audio.empty()) {
      throw std::runtime_error("Failed to load audio file (empty): " + audio_filename);
    }

    {
      original_duration = long_audio.size() / float(WHISPER_SAMPLE_RATE);
    }

    std::cout << "✓ Audio loaded successfully:" << std::endl;
    std::cout << "  - Samples: " << long_audio.size() << std::endl;
    std::cout << "  - Duration: " << original_duration << " seconds" << std::endl;
    std::cout << "  - Sample Rate: " << WHISPER_SAMPLE_RATE << " Hz" << std::endl;

    // Verify this is indeed long audio (60+ seconds)
    if (original_duration >= 60.0f) {
      std::cout << "✓ Confirmed long audio (>= 60 seconds)" << std::endl;
    } else {
      std::cout << "⚠ Warning: Audio shorter than 60s (" << original_duration << "s)" << std::endl;
    }

  } catch (const std::exception& e) {
    std::cerr << "✗ Error loading file: " << e.what() << std::endl;
    throw;
  }

  // Test 2: Audio preprocessing pipeline for long audio
  std::cout << "\n2. Testing audio preprocessing pipeline..." << std::endl;

  // Normalize the long audio
  auto normalized_audio = whisper::AudioProcessor::normalize_audio(long_audio);
  std::cout << "✓ Long audio normalization completed" << std::endl;

  // Test chunked preprocessing (essential for long audio)
  std::vector<std::vector<float>> audio_chunks;
  const int chunk_size_seconds = 30;
  const int chunk_samples = chunk_size_seconds * WHISPER_SAMPLE_RATE;

  std::cout << "  Processing in " << chunk_size_seconds << "-second chunks..." << std::endl;

  int num_chunks = 0;
  for (size_t start = 0; start < normalized_audio.size(); start += chunk_samples) {
    size_t end = std::min(start + chunk_samples, normalized_audio.size());
    std::vector<float> chunk(normalized_audio.begin() + start, normalized_audio.begin() + end);

    // Pad or trim chunk to standard size
    auto padded_chunk = Audio::pad_or_trim(chunk, WHISPER_CHUNK_SIZE);

    // Apply preemphasis
    auto filtered_chunk = whisper::AudioProcessor::apply_preemphasis(padded_chunk);

    audio_chunks.push_back(filtered_chunk);
    num_chunks++;

    if (num_chunks <= 3 || num_chunks % 10 == 0) {
      std::cout << "    Chunk " << num_chunks << ": " << chunk.size()
                << " -> " << filtered_chunk.size() << " samples" << std::endl;
    }
  }

  std::cout << "✓ Processed " << num_chunks << " chunks total" << std::endl;

  // Verify chunk count matches expected duration
  int expected_chunks = static_cast<int>(std::ceil(original_duration / chunk_size_seconds));
  if (std::abs(num_chunks - expected_chunks) <= 1) {
    std::cout << "✓ Chunk count matches expected (" << expected_chunks << " expected)" << std::endl;
  } else {
    std::cout << "⚠ Chunk count mismatch: got " << num_chunks << ", expected ~" << expected_chunks << std::endl;
  }

  // Test 3: Feature extraction for each chunk
  std::cout << "\n3. Testing feature extraction for long audio chunks..." << std::endl;

  FeatureExtractor extractor(80, 16000, 160, 30, 400);
  std::vector<Matrix> chunk_features;

  int processed_chunks = 0;
  for (const auto& chunk : audio_chunks) {
    auto features = extractor.extract(chunk);

    if (!features.empty()) {
      chunk_features.push_back(features);
      processed_chunks++;

      if (processed_chunks <= 3 || processed_chunks % 10 == 0) {
        std::cout << "    Chunk " << processed_chunks << " features: "
                  << features.size() << " x " << features[0].size() << std::endl;
      }
    }
  }

  std::cout << "✓ Extracted features from " << processed_chunks << " chunks" << std::endl;

  // Verify feature dimensions
  if (!chunk_features.empty()) {
    const auto& first_features = chunk_features[0];
    std::cout << "  - Feature dimensions: " << first_features.size() << " mel bins x "
              << first_features[0].size() << " time frames" << std::endl;

    // Check consistency across chunks
    bool consistent_dimensions = true;
    for (const auto& features : chunk_features) {
      if (features.size() != first_features.size() ||
          features[0].size() != first_features[0].size()) {
        consistent_dimensions = false;
        break;
      }
    }

    if (consistent_dimensions) {
      std::cout << "✓ Feature dimensions consistent across all chunks" << std::endl;
    } else {
      std::cout << "⚠ Feature dimensions vary across chunks" << std::endl;
    }
  }

  // Test 4: Memory usage analysis
  std::cout << "\n4. Testing memory usage for long audio processing..." << std::endl;

  // Calculate memory usage
  size_t audio_memory = long_audio.size() * sizeof(float);
  size_t chunk_memory = 0;
  size_t feature_memory = 0;

  for (const auto& chunk : audio_chunks) {
    chunk_memory += chunk.size() * sizeof(float);
  }

  for (const auto& features : chunk_features) {
    for (const auto& mel_bin : features) {
      feature_memory += mel_bin.size() * sizeof(float);
    }
  }

  std::cout << "  Memory usage analysis:" << std::endl;
  std::cout << "    - Original audio: " << (audio_memory / 1024 / 1024) << " MB" << std::endl;
  std::cout << "    - Processed chunks: " << (chunk_memory / 1024 / 1024) << " MB" << std::endl;
  std::cout << "    - Feature data: " << (feature_memory / 1024 / 1024) << " MB" << std::endl;

  // Verify memory usage is reasonable (less than 500MB total)
  size_t total_memory = audio_memory + chunk_memory + feature_memory;
  if (total_memory < 500 * 1024 * 1024) {
    std::cout << "✓ Total memory usage reasonable: " << (total_memory / 1024 / 1024) << " MB" << std::endl;
  } else {
    std::cout << "⚠ High memory usage: " << (total_memory / 1024 / 1024) << " MB" << std::endl;
  }

  // Test 5: Simulated transcription pipeline
  std::cout << "\n5. Testing simulated transcription pipeline..." << std::endl;

  // Simulate segment generation with proper timestamps
  std::vector<std::map<std::string, float>> mock_segments;

  float current_time = 0.0f;
  int segment_id = 0;

  for (int chunk_idx = 0; chunk_idx < processed_chunks; ++chunk_idx) {
    // Each chunk represents 30 seconds, create 2-3 segments per chunk
    int segments_per_chunk = 2 + (chunk_idx % 2); // 2 or 3 segments

    for (int seg = 0; seg < segments_per_chunk; ++seg) {
      float segment_duration = 30.0f / segments_per_chunk;
      float start_time = current_time;
      float end_time = current_time + segment_duration;

      std::map<std::string, float> segment;
      segment["id"] = static_cast<float>(segment_id);
      segment["start"] = start_time;
      segment["end"] = end_time;
      segment["chunk"] = static_cast<float>(chunk_idx);

      mock_segments.push_back(segment);

      current_time = end_time;
      segment_id++;
    }
  }

  std::cout << "  Generated " << mock_segments.size() << " mock segments" << std::endl;
  std::cout << "  Total coverage: 0.0s to " << current_time << "s" << std::endl;

  // Verify segment continuity and coverage
  bool segments_continuous = true;
  for (size_t i = 1; i < mock_segments.size(); ++i) {
    float prev_end = mock_segments[i-1]["end"];
    float curr_start = mock_segments[i]["start"];

    if (std::abs(curr_start - prev_end) > 0.1f) {
      segments_continuous = false;
      break;
    }
  }

  if (segments_continuous) {
    std::cout << "✓ Mock segments are continuous" << std::endl;
  } else {
    std::cout << "⚠ Mock segments have gaps" << std::endl;
  }

  // Verify total coverage matches audio duration
  float coverage_duration = current_time;
  if (std::abs(coverage_duration - original_duration) / original_duration < 0.1f) {
    std::cout << "✓ Segment coverage matches audio duration" << std::endl;
  } else {
    std::cout << "⚠ Coverage mismatch: " << coverage_duration << "s vs " << original_duration << "s" << std::endl;
  }

  // Test 6: Performance metrics
  std::cout << "\n6. Performance metrics summary..." << std::endl;

  float processing_ratio = static_cast<float>(processed_chunks * 30) / original_duration;
  std::cout << "  - Processing efficiency: " << (processing_ratio * 100) << "% of audio processed" << std::endl;
  std::cout << "  - Chunks per minute: " << (processed_chunks / (original_duration / 60.0f)) << std::endl;
  std::cout << "  - Average features per chunk: " << (chunk_features.empty() ? 0 :
                chunk_features[0].size() * chunk_features[0][0].size()) << std::endl;

  std::cout << "\n✅ Long Audio Integration Test Completed Successfully!" << std::endl;
  std::cout << "    Audio duration: " << original_duration << "s" << std::endl;
  std::cout << "    Chunks processed: " << processed_chunks << std::endl;
  std::cout << "    Features extracted: " << chunk_features.size() << " sets" << std::endl;
  std::cout << "    Mock segments: " << mock_segments.size() << std::endl;
}

/**
 * Test chunk boundary handling for continuous audio
 */
void test_chunk_boundary_continuity() {
  std::cout << "\n=== Chunk Boundary Continuity Test ===" << std::endl;

  // Create 90-second continuous sine wave (3 exact 30s chunks)
  const int duration_s = 90;
  const float frequency = 440.0f; // A4 note
  std::vector<float> continuous_audio(duration_s * WHISPER_SAMPLE_RATE);

  std::cout << "Creating " << duration_s << "-second continuous sine wave..." << std::endl;

  for (size_t i = 0; i < continuous_audio.size(); ++i) {
    float t = static_cast<float>(i) / WHISPER_SAMPLE_RATE;
    continuous_audio[i] = 0.5f * std::sin(2.0f * M_PI * frequency * t);
  }

  // Test 1: Verify signal continuity at chunk boundaries
  std::cout << "\n1. Testing signal continuity at 30s boundaries..." << std::endl;

  std::vector<int> boundary_samples = {
    30 * WHISPER_SAMPLE_RATE,  // 30s boundary
    60 * WHISPER_SAMPLE_RATE   // 60s boundary
  };

  for (int boundary : boundary_samples) {
    float boundary_time = static_cast<float>(boundary) / WHISPER_SAMPLE_RATE;

    // Check samples around boundary
    if (boundary > 10 && boundary < static_cast<int>(continuous_audio.size()) - 10) {
      float before = continuous_audio[boundary - 1];
      float at = continuous_audio[boundary];
      float after = continuous_audio[boundary + 1];

      // Calculate expected continuity (sine wave should be smooth)
      float expected_diff = std::abs(after - before);
      float actual_diff = std::abs(at - before) + std::abs(after - at);

      std::cout << "  Boundary at " << boundary_time << "s:" << std::endl;
      std::cout << "    Before: " << before << ", At: " << at << ", After: " << after << std::endl;

      if (actual_diff < expected_diff * 2.0f) {
        std::cout << "    ✓ Signal continuous at boundary" << std::endl;
      } else {
        std::cout << "    ⚠ Signal discontinuity detected" << std::endl;
      }
    }
  }

  // Test 2: Feature extraction across boundaries
  std::cout << "\n2. Testing feature extraction across boundaries..." << std::endl;

  FeatureExtractor extractor(80, 16000, 160, 30, 400);

  // Extract features for each 30s chunk
  std::vector<Matrix> boundary_features;

  for (int chunk = 0; chunk < 3; ++chunk) {
    int start_sample = chunk * 30 * WHISPER_SAMPLE_RATE;
    int end_sample = std::min(start_sample + 30 * WHISPER_SAMPLE_RATE,
                             static_cast<int>(continuous_audio.size()));

    std::vector<float> chunk_audio(continuous_audio.begin() + start_sample,
                                  continuous_audio.begin() + end_sample);

    auto features = extractor.extract(chunk_audio);
    boundary_features.push_back(features);

    std::cout << "  Chunk " << chunk << " (t=" << (chunk * 30) << "-" << ((chunk + 1) * 30)
              << "s): " << features.size() << " x " << features[0].size() << " features" << std::endl;
  }

  // Test 3: Feature consistency between adjacent chunks
  std::cout << "\n3. Testing feature consistency between chunks..." << std::endl;

  for (size_t chunk = 0; chunk < boundary_features.size() - 1; ++chunk) {
    const auto& curr_features = boundary_features[chunk];
    const auto& next_features = boundary_features[chunk + 1];

    // Compare last few frames of current chunk with first few frames of next chunk
    const int compare_frames = 5;

    if (curr_features[0].size() >= compare_frames && next_features[0].size() >= compare_frames) {
      float similarity_score = 0.0f;
      int comparisons = 0;

      for (int mel = 0; mel < std::min(static_cast<int>(curr_features.size()),
                                      static_cast<int>(next_features.size())); ++mel) {
        // Compare last few frames of current with first few of next
        for (int frame = 0; frame < compare_frames; ++frame) {
          int curr_frame = curr_features[mel].size() - compare_frames + frame;
          int next_frame = frame;

          float curr_val = curr_features[mel][curr_frame];
          float next_val = next_features[mel][next_frame];

          // Calculate similarity (inverse of difference)
          float diff = std::abs(curr_val - next_val);
          similarity_score += 1.0f / (1.0f + diff);
          comparisons++;
        }
      }

      similarity_score /= comparisons;

      std::cout << "  Chunks " << chunk << "-" << (chunk + 1)
                << " boundary similarity: " << similarity_score << std::endl;

      if (similarity_score > 0.7f) {
        std::cout << "    ✓ High similarity at boundary (smooth transition)" << std::endl;
      } else if (similarity_score > 0.5f) {
        std::cout << "    ~ Moderate similarity at boundary" << std::endl;
      } else {
        std::cout << "    ⚠ Low similarity at boundary (possible discontinuity)" << std::endl;
      }
    }
  }

  std::cout << "\n✅ Chunk Boundary Continuity Test Completed!" << std::endl;
}

/**
 * Test performance with different audio file sizes
 */
void test_audio_size_performance() {
  std::cout << "\n=== Audio Size Performance Test ===" << std::endl;

  struct PerformanceTest {
    int duration_seconds;
    std::string description;
    bool test_chunking;
  };

  std::vector<PerformanceTest> tests = {
    {30, "Standard 30s chunk", false},
    {60, "Double 60s audio", true},
    {120, "2-minute medium audio", true},
    {300, "5-minute long audio", true},
    {900, "15-minute very long audio (002-01.wav)", true}
  };

  FeatureExtractor extractor(80, 16000, 160, 30, 400);

  for (const auto& test : tests) {
    std::cout << "\nTesting " << test.description << "..." << std::endl;

    // Create synthetic audio of specified duration
    std::vector<float> test_audio(test.duration_seconds * WHISPER_SAMPLE_RATE);

    // Fill with varied frequency content to make it realistic
    for (size_t i = 0; i < test_audio.size(); ++i) {
      float t = static_cast<float>(i) / WHISPER_SAMPLE_RATE;
      test_audio[i] = 0.3f * std::sin(2.0f * M_PI * 440.0f * t) +
                     0.2f * std::sin(2.0f * M_PI * 880.0f * t) +
                     0.1f * std::sin(2.0f * M_PI * 220.0f * t * (1.0f + 0.1f * t));
    }

    // Test preprocessing
    auto normalized = whisper::AudioProcessor::normalize_audio(test_audio);
    std::cout << "  ✓ Normalization: " << test_audio.size() << " -> " << normalized.size() << " samples" << std::endl;

    if (test.test_chunking) {
      // Test chunked processing
      auto padded = Audio::pad_or_trim(normalized, WHISPER_CHUNK_SIZE);
      auto filtered = whisper::AudioProcessor::apply_preemphasis(padded);

      auto features_chunked = extractor.compute_mel_spectrogram(filtered, 160, 30);

      std::cout << "  ✓ Chunked features: " << features_chunked.size() << " x "
                << (features_chunked.empty() ? 0 : features_chunked[0].size()) << std::endl;

      // Also test full processing for comparison (if not too large)
      if (test.duration_seconds <= 300) { // Only for <= 5 minutes
        auto features_full = extractor.compute_mel_spectrogram(filtered, 160, std::nullopt);

        std::cout << "  ✓ Full features: " << features_full.size() << " x "
                  << (features_full.empty() ? 0 : features_full[0].size()) << std::endl;

        // Compare efficiency
        if (!features_chunked.empty() && !features_full.empty()) {
          float chunked_frames = features_chunked[0].size();
          float full_frames = features_full[0].size();
          float efficiency = chunked_frames / full_frames;

          std::cout << "  → Chunking efficiency: " << (efficiency * 100) << "% of full processing" << std::endl;
        }
      } else {
        std::cout << "  → Skipping full processing (too large)" << std::endl;
      }
    } else {
      // Test direct processing for short audio
      auto features = extractor.extract(test_audio);
      std::cout << "  ✓ Direct features: " << features.size() << " x "
                << (features.empty() ? 0 : features[0].size()) << std::endl;
    }

    // Memory usage estimate
    size_t audio_bytes = test_audio.size() * sizeof(float);
    size_t audio_mb = audio_bytes / (1024 * 1024);

    std::cout << "  → Audio memory: " << audio_mb << " MB" << std::endl;

    if (audio_mb > 100) {
      std::cout << "  ⚠ Large memory usage - chunking recommended" << std::endl;
    } else if (audio_mb > 50) {
      std::cout << "  ~ Moderate memory usage - consider chunking" << std::endl;
    } else {
      std::cout << "  ✓ Reasonable memory usage" << std::endl;
    }
  }

  std::cout << "\n✅ Audio Size Performance Test Completed!" << std::endl;
}

#ifndef TESTING_MODE

int main() {
  // Test standard audio files first
  test_whisper_audio("001.wav");
  test_whisper_audio("002-01.wav");

  // Run comprehensive long audio integration tests
  std::cout << "\n" << std::string(70, '=') << std::endl;
  std::cout << "Running Long Audio Integration Tests..." << std::endl;
  std::cout << std::string(70, '=') << std::endl;

  test_long_audio_integration("002-01.wav");
  test_chunk_boundary_continuity();
  test_audio_size_performance();

  demonstrate_usage();
  return 0;
}

#endif
